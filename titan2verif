#!/usr/bin/env python
import sys
import netCDF4
import numpy as np
import scipy.interpolate
import datetime
import copy
import argparse
import calendar
import time
import verif.data
import verif.input
import verif.util
import pyproj


def main():
   parser = argparse.ArgumentParser(description='A script to verify Titan output against trusted observations. The script aggregates the Titan observations in space and add it to an existing verif file. The verif file must already contain the verifying observations and this script will create "forecasts" for these locations.', add_help=False)
   parser.add_argument('file', help='Input text file from Titan')
   file = parser.add_argument_group('file options')
   file.add_argument('-o', help='Verif file', dest="ofilename", required=True)
   file.add_argument('-d', type=int, help='Date of input file in YYYYMMDD. Used to figure out where in the output file to write the "forecast".', dest='date', required=True)
   file.add_argument('-i', type=float, help='Time of day of input file in HH', dest='hour', required=True)
   file.add_argument('-v', metavar="COLUMN", default="value", help="What column from the file to show? If 'num', then show the number of total values.", dest="variable")
   file.add_argument('-c', help='Erase all forecasts in output file before adding values', dest='clear', action="store_true")
   file.add_argument('--multiply', metavar="FACTOR", type=float, default=1, help='Multiply all forecasts with this value')
   file.add_argument('--add', metavar="VALUE", type=float, default=0, help='Add this value to all forecasts (--multiply is done before --add)')
   file.add_argument('-k', metavar="FLAGS", type=verif.util.parse_numbers, help='If the file has a dqc column, only keep rows with these DQC flags. Comma-separated list accepted.', dest="keep")
   file.add_argument('-u', help='Write this to the units attribute in the output file.', dest="units")
   file.add_argument('--debug', help='Display debug information', action="store_true")
   agg = parser.add_argument_group('aggregation options', description='These options affect how the aggregated "forecast" is made.')
   agg.add_argument('-a', default="median", help='Function to aggregating observations. One of mean, median, min, max, or a number to specify a quantile.', dest='aggregator')
   agg.add_argument('-ed', metavar="HEIGHT", default=100, type=int, help='Use stations that are within this elevation difference', dest='min_elev_diff')
   agg.add_argument('-r', type=float, default=5, help='Radius of neighbourhood in km', dest='radius')
   agg.add_argument('-mn', metavar="NUM", type=int, default=3, help='Minimum number of stations required to create a "forecast"', dest='min_num')
   agg.add_argument('-proj', default="+proj=lcc +lat_0=63 +lon_0=15 +lat_1=63 +lat_2=63 +no_defs +R=6.371e+06", help='Projection to compute distances between stations', dest='proj')

   if len(sys.argv) == 1:
      parser.print_help()
      sys.exit(1)

   args = parser.parse_args()
   input = read_titan(args.file)
   if args.variable != "num" and args.variable not in input:
      verif.util.error("'%s' does not exist in '%s'" % (args.variable, args.file))

   output = verif.input.Netcdf(args.ofilename)
   locations = output.locations

   """
   Find the time and leadtime in output to write data to
   """
   leadtimes = output.leadtimes
   assert(len(leadtimes) == 1)
   assert(leadtimes[0] == 0)
   times = output.times
   Itime = np.where(times == verif.util.date_to_unixtime(args.date) + args.hour * 3600)[0]
   Ileadtime = 0
   if len(Itime) != 1:
      verif.util.error("Output file '%s' does not contain date and time" % args.ofilename)

   fcst = output.fcst
   if args.clear:
      fcst[:] = np.nan

   """
   Compute nearest neighbours
   """
   if "dqc" in input and args.keep is not None:
      qc = input["dqc"]
      num_before = len(qc)
      I = np.array([], 'int')
      for flag in args.keep:
         I = np.append(I, np.where(qc == flag)[0])
      for key in input:
         input[key] = input[key][I]
      num_removed = num_before - len(I)
      print "Number of values removed: %d" % num_removed
   lat = input["lat"]
   lon = input["lon"]
   proj = pyproj.Proj(args.proj)
   x, y = proj(lon, lat)

   if is_number(args.aggregator):
      func = verif.aggregator.Quantile(float(args.aggregator))
   else:
      func = verif.aggregator.get(args.aggregator)

   coords = np.zeros([len(x.flatten()), 2])
   coords[:, 0] = x
   coords[:, 1] = y
   nn_tree = scipy.spatial.KDTree(coords)
   for s in range(len(locations)):
      currlat = locations[s].lat
      currlon = locations[s].lon
      xx, yy = proj(currlon, currlat)
      I = nn_tree.query_ball_point([xx, yy], args.radius * 1000)
      if args.variable == "num":
         fcst[Itime, Ileadtime, s] = len(I)
      else:
         vals = input[args.variable][I]
         vals = vals[np.isnan(vals) == 0]
         if len(vals) > args.min_num:
            fcst[Itime, Ileadtime, s] = func(vals)

   # Write output
   output = netCDF4.Dataset(args.ofilename, 'a')
   output.variables["fcst"][:] = fcst[:]
   if args.units is not None:
      output.Units = args.units
   output.close()


def read_titan(ifilename):
   file = open(ifilename)
   values = dict()
   header = None

   for line in file:
      if header is None:
         header = [word for word in line.strip().split(';') if word != '']
         for word in header:
            values[word] = list()
         continue
      curr = line.strip().split(';')
      for i, col in enumerate(header):
         val = curr[i]
         if is_number(val):
            val = float(val)
         else:
            val = -999
         values[col] += [val]

   for col in header:
      values[col] = np.array(values[col])

   file.close()
   return values


def is_number(s):
   try:
      float(s)
      return True
   except ValueError:
      return False


if __name__ == "__main__":
   main()
